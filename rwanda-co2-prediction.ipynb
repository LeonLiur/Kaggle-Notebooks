{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/leonliur/rwanda-co2-prediction-lb-9?scriptVersionId=149364745\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"1e48828f","metadata":{"papermill":{"duration":0.008181,"end_time":"2023-11-05T04:37:39.699798","exception":false,"start_time":"2023-11-05T04:37:39.691617","status":"completed"},"tags":[]},"source":["# Progress & versions 🚀\n","\n","| Changes  | CV Score LGBM | CV Score XGB | CV Score RF |\n","|----------|---------------|--------------|----------|\n","| Baseline | 19.92164              | 24.86644             |\n","| Removed features > 0.5 NaN         |               |24.61487              ||\n","| Imputed rest of NaN with mean         |               | 24.75321             ||\n","| Implemented scalar |  | 24.34700 ||\n","| Covid flag | | 23.36592||\n","| sin cos weeks | | 23.69442||\n","| is zero | | 24.47380 ||\n","| 8-features | | 19.58470|\n","| Clustered | | 15.70909 | | \n","| Dist_to_max | | 15.50617 | |\n","| PCA | | 14.81864 | 12.52867|\n","| Max Emission Week Station | | 11.50131 |"]},{"cell_type":"markdown","id":"91c38da9","metadata":{"papermill":{"duration":0.007244,"end_time":"2023-11-05T04:37:39.715009","exception":false,"start_time":"2023-11-05T04:37:39.707765","status":"completed"},"tags":[]},"source":["# Importing Libraries 📚"]},{"cell_type":"code","execution_count":1,"id":"4f909482","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-05T04:37:39.732914Z","iopub.status.busy":"2023-11-05T04:37:39.732382Z","iopub.status.idle":"2023-11-05T04:37:45.449521Z","shell.execute_reply":"2023-11-05T04:37:45.448267Z"},"papermill":{"duration":5.730008,"end_time":"2023-11-05T04:37:45.452677","exception":false,"start_time":"2023-11-05T04:37:39.722669","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import datetime as dt\n","import haversine as hs\n","\n","from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","from tqdm import tqdm\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor, plot_importance\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans"]},{"cell_type":"code","execution_count":2,"id":"44a8c40a","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:45.470634Z","iopub.status.busy":"2023-11-05T04:37:45.470104Z","iopub.status.idle":"2023-11-05T04:37:45.475153Z","shell.execute_reply":"2023-11-05T04:37:45.47397Z"},"papermill":{"duration":0.017276,"end_time":"2023-11-05T04:37:45.477856","exception":false,"start_time":"2023-11-05T04:37:45.46058","status":"completed"},"tags":[]},"outputs":[],"source":["GPU = False"]},{"cell_type":"code","execution_count":3,"id":"42559ce1","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:45.496041Z","iopub.status.busy":"2023-11-05T04:37:45.494968Z","iopub.status.idle":"2023-11-05T04:37:49.059142Z","shell.execute_reply":"2023-11-05T04:37:49.057905Z"},"papermill":{"duration":3.576382,"end_time":"2023-11-05T04:37:49.062263","exception":false,"start_time":"2023-11-05T04:37:45.485881","status":"completed"},"tags":[]},"outputs":[],"source":["df_og = pd.read_csv(\"../input/rwanda-kfolds/train_folds.csv\")\n","df_test_og = pd.read_csv(\"/kaggle/input/playground-series-s3e20/test.csv\")\n","sample_submission = pd.read_csv(\"/kaggle/input/playground-series-s3e20/sample_submission.csv\")"]},{"cell_type":"markdown","id":"0651e374","metadata":{"papermill":{"duration":0.007463,"end_time":"2023-11-05T04:37:49.079617","exception":false,"start_time":"2023-11-05T04:37:49.072154","status":"completed"},"tags":[]},"source":["# Cleaning & Preprocessing ⚙️"]},{"cell_type":"markdown","id":"08940915","metadata":{"papermill":{"duration":0.007481,"end_time":"2023-11-05T04:37:49.095025","exception":false,"start_time":"2023-11-05T04:37:49.087544","status":"completed"},"tags":[]},"source":["Since I only ended up using only the indexing features (lon, lat, week, year, etc...), I did not need to do much preprocessing and cleaning"]},{"cell_type":"code","execution_count":4,"id":"00273e5d","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.11237Z","iopub.status.busy":"2023-11-05T04:37:49.111932Z","iopub.status.idle":"2023-11-05T04:37:49.11802Z","shell.execute_reply":"2023-11-05T04:37:49.116597Z"},"papermill":{"duration":0.018006,"end_time":"2023-11-05T04:37:49.12085","exception":false,"start_time":"2023-11-05T04:37:49.102844","status":"completed"},"tags":[]},"outputs":[],"source":["def cleaning(df):\n","    return df.drop([\"ID_LAT_LON_YEAR_WEEK\"], axis=1)"]},{"cell_type":"code","execution_count":5,"id":"358f3f99","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.139366Z","iopub.status.busy":"2023-11-05T04:37:49.13823Z","iopub.status.idle":"2023-11-05T04:37:49.145549Z","shell.execute_reply":"2023-11-05T04:37:49.144112Z"},"papermill":{"duration":0.019503,"end_time":"2023-11-05T04:37:49.148315","exception":false,"start_time":"2023-11-05T04:37:49.128812","status":"completed"},"tags":[]},"outputs":[],"source":["def feature_preprocessing(df, drop_na_threshold):\n","#     # truncate columns with < 0.5 NA\n","#     missing_ratios = df.isnull().mean()\n","#     columns_to_drop = missing_ratios[missing_ratios > drop_na_threshold].index\n","#     df = df.drop(columns_to_drop, axis=1)\n","    \n","#     # impute the rest with mean\n","#     df = df.fillna(df.mean())\n","    \n","\n","    # scalar is causing problems\n","#     sc = StandardScaler()\n","#     for i in df.columns:\n","#         if i not in [\"emission\", \"covid_flag\", \"week_no\", \"year\", \"latitude\", \"longitude\", \"kfold\"]:\n","#             df[i] = sc.fit_transform(df[i].values.reshape(-1,1))\n","    return df"]},{"cell_type":"code","execution_count":6,"id":"b9200e8d","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.166287Z","iopub.status.busy":"2023-11-05T04:37:49.16552Z","iopub.status.idle":"2023-11-05T04:37:49.170899Z","shell.execute_reply":"2023-11-05T04:37:49.169725Z"},"papermill":{"duration":0.01771,"end_time":"2023-11-05T04:37:49.173775","exception":false,"start_time":"2023-11-05T04:37:49.156065","status":"completed"},"tags":[]},"outputs":[],"source":["def feature_preprocessing_inf(df, drop_na_threshold, scaler):\n","    # truncate columns with < 0.5 NA\n","#     missing_ratios = df.isnull().mean()\n","#     columns_to_drop = missing_ratios[missing_ratios > drop_na_threshold].index\n","#     df = df.drop(columns_to_drop, axis=1)\n","    \n","    # impute the rest with mean\n","#     df = df.fillna(df.mean())\n","    \n","#     sc = StandardScaler()\n","#     for i in df.columns:\n","#         if i not in [\"emission\", \"covid_flag\", \"week_no\", \"year\", \"latitude\", \"longitude\", \"kfold\"]:\n","#             df[i] = sc.fit_transform(df[i].values.reshape(-1,1))\n","    return df"]},{"cell_type":"markdown","id":"197acd57","metadata":{"papermill":{"duration":0.007733,"end_time":"2023-11-05T04:37:49.189394","exception":false,"start_time":"2023-11-05T04:37:49.181661","status":"completed"},"tags":[]},"source":["# Feature Engineering 🔎"]},{"cell_type":"markdown","id":"c4d80041","metadata":{"papermill":{"duration":0.008047,"end_time":"2023-11-05T04:37:49.205501","exception":false,"start_time":"2023-11-05T04:37:49.197454","status":"completed"},"tags":[]},"source":["Here are the additional features I added\n","- cartesian rotation: these are inspired by this [medium post](https://bmanikan.medium.com/feature-engineering-all-i-learned-about-geo-spatial-features-649871d16796), where it is shown that rotating the longitude, latitude, and computing polar coordinates help\n","- month: the month of the recorded emission\n","- PCA: principal component analysis on the longitude and latitude"]},{"cell_type":"code","execution_count":7,"id":"8703cfa5","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.223817Z","iopub.status.busy":"2023-11-05T04:37:49.22342Z","iopub.status.idle":"2023-11-05T04:37:49.236223Z","shell.execute_reply":"2023-11-05T04:37:49.235254Z"},"papermill":{"duration":0.027665,"end_time":"2023-11-05T04:37:49.241144","exception":false,"start_time":"2023-11-05T04:37:49.213479","status":"completed"},"tags":[]},"outputs":[],"source":["def rotation(df):\n","    df['rot_45_x'] = (0.707 * df['latitude']) + (0.707 * df['longitude'])\n","    df['rot_45_y'] = (0.707 * df['longitude']) + (0.707 * df['latitude'])\n","    df['rot_30_x'] = (0.866 * df['latitude']) + (0.5 * df['longitude'])\n","    df['rot_30_y'] = (0.866 * df['longitude']) + (0.5 * df['latitude'])\n","    df['r'] = np.sqrt(df['longitude']**2 + df['latitude']**2)\n","    df['phi'] = np.arctan2(df['latitude'], df['longitude'])\n","    return df\n","\n","def get_month(row):\n","    date = dt.datetime.strptime(f'{int(row.year)}-{int(row.week_no)+1}-1', \"%Y-%W-%w\")\n","    return date.month\n","\n","def find_distance(row, max_emissions):\n","    return hs.haversine((max_emissions[int(row.kmeans_group)][0], max_emissions[int(row.kmeans_group)][1]),(row.latitude, row.longitude))\n","\n","def pca(df):\n","    coordinates = df[['latitude','longitude']].values\n","    pca_obj = PCA()\n","    pca_coordinates = pca_obj.fit_transform(coordinates)\n","    \n","    df['pca_x'] = pca_coordinates[:, 0]\n","    df['pca_y'] = pca_coordinates[:, 1]\n","    return df"]},{"cell_type":"markdown","id":"b6749d63","metadata":{"papermill":{"duration":0.00826,"end_time":"2023-11-05T04:37:49.257586","exception":false,"start_time":"2023-11-05T04:37:49.249326","status":"completed"},"tags":[]},"source":["More features!\n","- week_sin and week_cos are **cyclical** time features, this way week 51 can be seen as close to week 1\n","- covid flag flags covid months\n","- cluster: KMeans clustering was performed on the coordinates to group recorded areas into five groups near each other\n","- dist_to_max: the distance between the recorded location and the maximum CO2 location in the same cluster\n","- emission_zero: there are some entries with zero emission across the time frame\n","- stationID: the location where the data was recorded\n","- max_emission_week_station: **this is an important feature**: inspired by [this notebook](https://www.kaggle.com/code/danbraswell/no-ml-public-lb-23-02231/notebook), we can see that the maximum emission for any location for any week across three years give a good clue at the final emission. Therefore I have incorporated this feature as part of my feature engineering"]},{"cell_type":"code","execution_count":8,"id":"50bfa71b","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.276405Z","iopub.status.busy":"2023-11-05T04:37:49.27596Z","iopub.status.idle":"2023-11-05T04:37:49.292706Z","shell.execute_reply":"2023-11-05T04:37:49.291528Z"},"papermill":{"duration":0.029145,"end_time":"2023-11-05T04:37:49.295451","exception":false,"start_time":"2023-11-05T04:37:49.266306","status":"completed"},"tags":[]},"outputs":[],"source":["N_CLUSTERS = 5\n","\n","def feature_engineering(df):\n","    # cos and sin to week\n","    df[\"week_sin\"] = np.sin(df[\"week_no\"] / 52 * 2 * np.pi)\n","    df[\"week_cos\"] = np.cos(df[\"week_no\"] / 52 * 2 * np.pi)\n","    \n","    # covid flag\n","    df[\"covid_flag\"] = np.where((df[\"year\"] == 2020) & (df[\"week_no\"] >= 11) & (df[\"week_no\"] <= 40), 1, 0)\n","    \n","    df = rotation(df)\n","    \n","    # cluster K means: elbow point at 5\n","    cluster_df = df.groupby(by=['latitude', 'longitude'], as_index=False)['emission'].mean()\n","    model = KMeans(n_clusters=N_CLUSTERS, n_init='auto')\n","    cluster_df['kmeans_group'] = model.fit_predict(cluster_df)\n","    \n","    # calculate distance to most in emission\n","    idx = cluster_df.groupby(\"kmeans_group\")[\"emission\"].transform(max) == cluster_df[\"emission\"]\n","    max_emission_indices = cluster_df.loc[idx]\n","    max_emissions = []\n","    for cluster_no in range(N_CLUSTERS):\n","        lon, lat = max_emission_indices.loc[max_emission_indices.kmeans_group == cluster_no, [\"latitude\", \"longitude\"]].values[0]\n","        max_emissions.append((lon, lat))\n","    cluster_df[\"dist_to_max\"] = cluster_df.apply(lambda row : find_distance(row, max_emissions), axis=1) \n","    \n","    # there are some 0 emissions we need to avoid\n","    df[\"emission_zero\"] = np.where(df[\"emission\"] == 0, 1, 0)\n","    \n","    # month column\n","    df[\"month\"] = df.apply(lambda row : get_month(row), axis=1)\n","    \n","    # pca\n","    df = pca(df)\n","    \n","    # adding station ID and max emission across three years\n","    unique_stations = set(zip(df[\"latitude\"], df[\"longitude\"]))\n","    station_mapping = {tuple(station): index + 1 for index, station in enumerate(unique_stations)}\n","    df[\"station_id\"] = df.apply(lambda row : station_mapping[(row['latitude'], row['longitude'])], axis=1)\n","    max_emissions = df.groupby(by=[\"station_id\", \"week_no\"])[\"emission\"].max().reset_index().rename(columns={\"emission\":\"max_emission_week_station\"})\n","\n","    df = df.merge(max_emissions, on=['station_id', 'week_no'], how='left')\n","    df = df.merge(cluster_df[[\"latitude\", \"longitude\", \"kmeans_group\", \"dist_to_max\"]], on=[\"latitude\", \"longitude\"])\n","    \n","    return df"]},{"cell_type":"code","execution_count":9,"id":"fe49045d","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.313284Z","iopub.status.busy":"2023-11-05T04:37:49.312638Z","iopub.status.idle":"2023-11-05T04:37:49.333009Z","shell.execute_reply":"2023-11-05T04:37:49.331853Z"},"papermill":{"duration":0.03291,"end_time":"2023-11-05T04:37:49.33608","exception":false,"start_time":"2023-11-05T04:37:49.30317","status":"completed"},"tags":[]},"outputs":[],"source":["def feature_engineering_test(df, df_test):\n","    # cos and sin to week\n","    df[\"week_sin\"] = np.sin(df[\"week_no\"] / 52 * 2 * np.pi)\n","    df_test[\"week_sin\"] = np.sin(df_test[\"week_no\"] / 52 * 2 * np.pi)\n","    \n","    df[\"week_cos\"] = np.cos(df[\"week_no\"] / 52 * 2 * np.pi)\n","    df_test[\"week_cos\"] = np.cos(df_test[\"week_no\"] / 52 * 2 * np.pi)\n","    \n","    # covid flag\n","    df[\"covid_flag\"] = np.where((df[\"year\"] == 2020) & (df[\"week_no\"] >= 11) & (df[\"week_no\"] <= 40), 1, 0)\n","    df_test[\"covid_flag\"] = np.where((df_test[\"year\"] == 2020) & (df_test[\"week_no\"] >= 11) & (df_test[\"week_no\"] <= 40), 1, 0)\n","    \n","    df = rotation(df)\n","    df_test = rotation(df_test)\n","    \n","    # cluster K means: elbow point at 5\n","    cluster_df = df.groupby(by=['latitude', 'longitude'], as_index=False)['emission'].mean()\n","    model = KMeans(n_clusters=N_CLUSTERS, n_init='auto')\n","    cluster_df['kmeans_group'] = model.fit_predict(cluster_df)\n","    \n","    # calculate distance to most in emission\n","    idx = cluster_df.groupby(\"kmeans_group\")[\"emission\"].transform(max) == cluster_df[\"emission\"]\n","    max_emission_indices = cluster_df.loc[idx]\n","    max_emissions = []\n","    for cluster_no in range(N_CLUSTERS):\n","        lon, lat = max_emission_indices.loc[max_emission_indices.kmeans_group == cluster_no, [\"latitude\", \"longitude\"]].values[0]\n","        max_emissions.append((lon, lat))\n","    cluster_df[\"dist_to_max\"] = cluster_df.apply(lambda row : find_distance(row, max_emissions), axis=1) \n","    \n","    # there are some 0 emissions we need to avoid\n","    cluster_df[\"emission_zero\"] = np.where(cluster_df[\"emission\"] == 0, 1, 0)\n","    \n","    # month column\n","    df[\"month\"] = df.apply(lambda row : get_month(row), axis=1)\n","    df_test[\"month\"] = df.apply(lambda row : get_month(row), axis=1)\n","    \n","    # PCA\n","    df = pca(df)\n","    df_test = pca(df_test)\n","    \n","    # adding station ID and max emission across three years\n","    unique_stations = set(zip(df[\"latitude\"], df[\"longitude\"]))\n","    station_mapping = {tuple(station): index + 1 for index, station in enumerate(unique_stations)}\n","    df[\"station_id\"] = df.apply(lambda row : station_mapping[(row['latitude'], row['longitude'])], axis=1)\n","    df_test[\"station_id\"] = df_test.apply(lambda row : station_mapping[(row['latitude'], row['longitude'])], axis=1)    \n","    max_emissions = df.groupby(by=[\"station_id\", \"week_no\"])[\"emission\"].max().reset_index().rename(columns={\"emission\":\"max_emission_week_station\"})\n","    \n","    # merging max emission station data\n","    df = df.merge(max_emissions, on=['station_id', 'week_no'], how='left')\n","    df_test = df_test.merge(max_emissions, on=['station_id', 'week_no'], how='left')\n","    \n","    # merging distance to max emission data\n","    df = df.merge(cluster_df[[\"latitude\", \"longitude\", \"kmeans_group\", \"emission_zero\", \"dist_to_max\"]], on=[\"latitude\", \"longitude\"])\n","    df_test = df_test.merge(cluster_df[[\"latitude\", \"longitude\", \"kmeans_group\", \"emission_zero\", \"dist_to_max\"]], on=[\"latitude\", \"longitude\"])\n","    \n","    return df,df_test"]},{"cell_type":"markdown","id":"a8d0a1da","metadata":{"papermill":{"duration":0.008331,"end_time":"2023-11-05T04:37:49.352453","exception":false,"start_time":"2023-11-05T04:37:49.344122","status":"completed"},"tags":[]},"source":["# Model Training & Inference 🪁"]},{"cell_type":"code","execution_count":10,"id":"a314bb77","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.370247Z","iopub.status.busy":"2023-11-05T04:37:49.369785Z","iopub.status.idle":"2023-11-05T04:37:49.397223Z","shell.execute_reply":"2023-11-05T04:37:49.396032Z"},"papermill":{"duration":0.039866,"end_time":"2023-11-05T04:37:49.400062","exception":false,"start_time":"2023-11-05T04:37:49.360196","status":"completed"},"tags":[]},"outputs":[],"source":["def go_kfold(df, features, df_test=None, weights=(1,1,1), coef=1, INFERENCE=False):\n","    coefficients = [x / sum(weights) for x in weights]\n","    \n","    cv_scores_xgb = []\n","    cv_scores_lgbm = []\n","    cv_scores_rf = []\n","    cv_scores_assemble = []\n","    \n","    if INFERENCE:\n","        final_predictions_xgb = []\n","        final_predictions_lgbm = []\n","        final_predictions_rf = []\n","        final_predictions_assemble = []\n","        X_test = df_test[features]\n","\n","    for fold in range(5):\n","        X_train = df[df.kfold != fold]\n","        X_valid = df[df.kfold == fold].reset_index(drop=True)\n","\n","        y_train = X_train.emission\n","        y_valid = X_valid.emission\n","\n","        X_train = X_train[features]\n","        X_valid = X_valid[features]\n","\n","        print(\"--\")\n","        \n","        preds_valid_assemble = np.zeros(len(X_valid))\n","        if INFERENCE:\n","            test_preds_assemble = np.zeros(len(X_test))\n","\n","        if weights[0] != 0:\n","            if GPU:\n","                model_xgb = XGBRegressor(random_state=fold, n_jobs=4, tree_method=\"gpu_hist\", gpu_id=0, predictor=\"gpu_predictor\")\n","            else:\n","                model_xgb = XGBRegressor(random_state=fold, n_jobs=4)\n","            model_xgb.fit(X_train, y_train)\n","            preds_valid_xgb = model_xgb.predict(X_valid) * coef\n","            preds_valid_assemble += preds_valid_xgb * coefficients[0]\n","            cv_score_xgb = mean_squared_error(y_valid, preds_valid_xgb, squared=False)\n","            cv_scores_xgb.append(cv_score_xgb)\n","\n","            print(fold,\"RMSE for XGB:\", cv_score_xgb)\n","            \n","            if INFERENCE:\n","                test_preds_xgb = model_xgb.predict(X_test) * coef\n","                final_predictions_xgb.append(test_preds_xgb)\n","                test_preds_assemble += test_preds_xgb * coefficients[0]\n","\n","        if weights[1] != 0:\n","            model_lgbm = LGBMRegressor(n_estimators = 1000, max_depth = 15, learning_rate = 0.01, num_leaves = 105)\n","            model_lgbm.fit(X_train, y_train)\n","            preds_valid_lgbm = model_lgbm.predict(X_valid) * coef\n","            preds_valid_assemble += preds_valid_lgbm * coefficients[1]\n","            cv_score_lgbm = mean_squared_error(y_valid, preds_valid_lgbm, squared=False)\n","            cv_scores_lgbm.append(cv_score_lgbm)\n","\n","            print(fold,\"RMSE for LGBM:\", cv_score_lgbm)\n","            \n","            if INFERENCE:\n","                test_preds_lgbm = model_lgbm.predict(X_test) * coef\n","                final_predictions_lgbm.append(test_preds_lgbm)\n","                test_preds_assemble += test_preds_lgbm * coefficients[1]\n","        \n","        if weights[2] != 0:\n","            model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n","            model_rf.fit(X_train, y_train)\n","            preds_valid_rf = model_rf.predict(X_valid) * coef\n","            preds_valid_assemble += preds_valid_rf * coefficients[2]\n","            cv_score_rf = mean_squared_error(y_valid, preds_valid_rf, squared=False)\n","            cv_scores_rf.append(cv_score_rf)\n","\n","            print(fold,\"RMSE for RF:\", cv_score_rf)\n","            \n","            if INFERENCE:\n","                test_preds_rf = model_rf.predict(X_test) * coef\n","                final_predictions_rf.append(test_preds_rf)\n","                test_preds_assemble += test_preds_rf * coefficients[2]\n","        \n","        # get CV score for assembled\n","        cv_score_assemble = mean_squared_error(y_valid, preds_valid_assemble, squared=False)\n","        cv_scores_assemble.append(cv_score_assemble)\n","\n","        print(fold, \"RMSE for assemble: \", cv_score_assemble)\n","        \n","        if INFERENCE:\n","            final_predictions_assemble.append(test_preds_assemble)\n","        \n","    print(\"--\")\n","    \n","    if weights[0]:\n","        print(\"Mean RMSE for XGB:\", np.mean(cv_scores_xgb), \"| XGB std RMSE\", np.std(cv_scores_xgb))\n","    if weights[1]:\n","        print(\"Mean RMSE for LGBM:\", np.mean(cv_scores_lgbm), \"| LGBM std RMSE\", np.std(cv_scores_lgbm))    \n","    if weights[2]:\n","        print(\"Mean RMSE for RF:\", np.mean(cv_scores_rf), \"| RF std RMSE\", np.std(cv_scores_rf))\n","    print(\"Mean RMSE for Assemble:\", np.mean(cv_scores_assemble), \"| Assemble std RMSE\", np.std(cv_scores_assemble))\n","    \n","    if INFERENCE:\n","        xgb_predictions = np.zeros(df_test.shape[0]) if weights[0] == 0 else np.mean(np.column_stack(final_predictions_xgb), axis=1)\n","        lgbm_predictions = np.zeros(df_test.shape[0]) if weights[1] == 0 else np.mean(np.column_stack(final_predictions_lgbm), axis=1)\n","        rf_predictions = np.zeros(df_test.shape[0]) if weights[2] == 0 else np.mean(np.column_stack(final_predictions_rf), axis=1)\n","\n","        sample_submission.emission = np.mean(np.column_stack(final_predictions_assemble), axis=1)\n","        sample_submission.to_csv(\"submission.csv\", index=False)\n","        print(\"--\\nKFOLD INFERENCE DONE\")"]},{"cell_type":"code","execution_count":11,"id":"d32de5d7","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.417801Z","iopub.status.busy":"2023-11-05T04:37:49.417358Z","iopub.status.idle":"2023-11-05T04:37:49.43215Z","shell.execute_reply":"2023-11-05T04:37:49.431176Z"},"papermill":{"duration":0.026712,"end_time":"2023-11-05T04:37:49.434597","exception":false,"start_time":"2023-11-05T04:37:49.407885","status":"completed"},"tags":[]},"outputs":[],"source":["def inference_whole_data(df, df_test, features, weights=(1,1,1), coef=1):\n","    coefficients = [x / sum(weights) for x in weights]\n","\n","    final_predictions_xgb = []\n","    final_predictions_lgbm = []\n","    final_predictions_rf = []\n","    X_test = df_test[features]\n","\n","    X_train = df[features]\n","    y_train = df.emission\n","\n","    if weights[0] != 0:\n","        if GPU:\n","            model_xgb = XGBRegressor(random_state=42, n_jobs=4, tree_method=\"gpu_hist\", gpu_id=0, predictor=\"gpu_predictor\")\n","        else:\n","            model_xgb = XGBRegressor(random_state=42, n_jobs=4)\n","        model_xgb.fit(X_train, y_train)\n","        final_predictions_xgb.append(model_xgb.predict(X_test))\n","\n","    if weights[1] != 0:\n","        model_lgbm = LGBMRegressor(n_estimators = 1000, max_depth = 15, learning_rate = 0.01, num_leaves = 105)\n","        model_lgbm.fit(X_train, y_train)\n","        final_predictions_lgbm.append(model_lgbm.predict(X_test))\n","\n","    if weights[2] != 0:\n","        model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n","        model_rf.fit(X_train, y_train)\n","        final_predictions_rf.append(model_rf.predict(X_test))\n","\n","    xgb_predictions =  np.zeros(df_test.shape[0]) if weights[0] == 0 else np.mean(np.column_stack(final_predictions_xgb), axis=1)\n","    lgbm_predictions = np.zeros(df_test.shape[0]) if weights[1] == 0 else np.mean(np.column_stack(final_predictions_lgbm), axis=1)\n","    rf_predictions = np.zeros(df_test.shape[0]) if weights[2] == 0 else np.mean(np.column_stack(final_predictions_rf), axis=1)\n","                    \n","    sample_submission.emission = coefficients[0] * xgb_predictions + coefficients[1] * lgbm_predictions + coefficients[2] * rf_predictions\n","    sample_submission.emission = sample_submission.emission * coef\n","    sample_submission.to_csv(\"submission.csv\", index=False)\n","    print(\"--\\nINFERENCE W/ WHOLE DATA DONE\")    "]},{"cell_type":"code","execution_count":12,"id":"e6d629b2","metadata":{"execution":{"iopub.execute_input":"2023-11-05T04:37:49.452386Z","iopub.status.busy":"2023-11-05T04:37:49.451673Z","iopub.status.idle":"2023-11-05T04:43:11.187938Z","shell.execute_reply":"2023-11-05T04:43:11.186256Z"},"papermill":{"duration":321.748312,"end_time":"2023-11-05T04:43:11.190813","exception":false,"start_time":"2023-11-05T04:37:49.442501","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--\n","0 RMSE for RF: 16.712992437117336\n","0 RMSE for assemble:  16.712992437117336\n","--\n","1 RMSE for RF: 19.64012233093327\n","1 RMSE for assemble:  19.64012233093327\n","--\n","2 RMSE for RF: 27.348100665208765\n","2 RMSE for assemble:  27.348100665208765\n","--\n","3 RMSE for RF: 13.808304245200288\n","3 RMSE for assemble:  13.808304245200288\n","--\n","4 RMSE for RF: 13.805210729175922\n","4 RMSE for assemble:  13.805210729175922\n","--\n","Mean RMSE for RF: 18.262946081527115 | RF std RMSE 5.030988827113296\n","Mean RMSE for Assemble: 18.262946081527115 | Assemble std RMSE 5.030988827113296\n","--\n","KFOLD INFERENCE DONE\n"]}],"source":["INFERENCE = True\n","vital_features = [\"ID_LAT_LON_YEAR_WEEK\", \"week_no\", \"year\", \"latitude\", \"longitude\", \"emission\", \"kfold\"]\n","\n","if INFERENCE:\n","    df = df_og.copy()[vital_features]\n","    df = cleaning(df)\n","    df = feature_preprocessing(df, 0.5)\n","    df_test = df_test_og.copy()\n","    df_test = cleaning(df_test)\n","    df_test = feature_preprocessing(df_test, 0.5)\n","    \n","    df, df_test = feature_engineering_test(df, df_test)\n","    features = [x for x in df.columns if x not in ('emission', 'kfold')]\n","    go_kfold(df, features, weights=(0, 0, 1), coef=1.07, df_test=df_test, INFERENCE=True)\n","else:\n","    df = df_og.copy()[vital_features]\n","    df = cleaning(df)\n","    df = feature_preprocessing(df, 0.5)\n","\n","    df = feature_engineering(df)\n","    features = [x for x in df.columns if x not in ('emission', 'kfold')]\n","    go_kfold(df, features, weights=(0, 0, 1), coef=1.07, INFERENCE=False)"]},{"cell_type":"markdown","id":"107088b2","metadata":{"papermill":{"duration":0.008282,"end_time":"2023-11-05T04:43:11.207844","exception":false,"start_time":"2023-11-05T04:43:11.199562","status":"completed"},"tags":[]},"source":["# That's it! 🧨"]},{"cell_type":"markdown","id":"8fc603b7","metadata":{"papermill":{"duration":0.009548,"end_time":"2023-11-05T04:43:11.226091","exception":false,"start_time":"2023-11-05T04:43:11.216543","status":"completed"},"tags":[]},"source":["I think there is definitely room for this notebook to perform better, however, this is also a learning process for me. Please give me some feedback on how to improve!"]},{"cell_type":"code","execution_count":null,"id":"011d6e5b","metadata":{"papermill":{"duration":0.008782,"end_time":"2023-11-05T04:43:11.243675","exception":false,"start_time":"2023-11-05T04:43:11.234893","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":346.83417,"end_time":"2023-11-05T04:43:12.780379","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-05T04:37:25.946209","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}